incarnation: scafi

_constants:
  initialClock: &initial_clock 1.0
  retentionTime: &retentionTime 5
  exportInterval: &exportInterval 2
  actionSpace: &actionSpace List(1.0, 2.0, 3.0, 4.0, 5.0)
  windowHistory: &windowHistory 5

variables:
  random: &random
    min: 0
    max: 16
    step: 1
    default: 2

  weight:  &weight
    type: ArbitraryVariable
    parameters: [1.0, [1.0, 0.99, 0.95, 0.8, 0.5]]
  batchSize: { formula: 256, language: scala }
  episodeLength: &episodeLength { formula: 200, language: scala }
  samplingEpisodes: &samplingEpisodes { formula: episodeLength - 0.0001 }
  bufferSize: { formula: 10000, language: scala }
  episodes: &episodes { formula: 40, language: scala }
  totalEpisodes: &totalEpisodes { formula: episodes * episodeLength }
  width: &width { formula: 500.0, language: scala }
  spacing: &spacing { formula: 50.0, language: scala }
  randomness: &randomness { formula: 25.0, language: scala }

  range: &range
    formula: 75
    language: scala
  actionSpaceEvaluated: &actionSpaceEvaluated
    formula: *actionSpace
    language: scala

  learningInfo: &learningInfo
    formula: |
      import it.unibo.scripting._;
      it.unibo.learning.LearningInfo(
        random.as[Double].toInt, 
        bufferSize.as[Int], 
        batchSize.as[Int],
        episodeLength.as[Int]
      )
    language: scala

  environmentBox: &environmentBox
    formula: |
      import it.unibo.scripting._;
      it.unibo.learning.Box(width.as[Double], spacing.as[Double], randomness.as[Double])
    language: scala

  neuralNet: &neuralNet
    formula: |
      import it.unibo.learning.network.torch.torch;
      import it.unibo.learning.network._;
      import it.unibo.scripting._;
      torch.manual_seed(random.as[Double].toInt);
      new MLPTemporal(
        hiddenSize = 128, 
        snapshots = 5,
        actionSpace = actionSpaceEvaluated.as[List[Double]]
      )
    language: scala
  learner: &learner
    formula: |
      import it.unibo.learning.abstractions.DecayReference;
      import it.unibo.learning.agents.DeepQLearning;
      import it.unibo.learning.network.NeuralNetworkRL;
      import it.unibo.scripting._;
      new DeepQLearning(
        epsilon = DecayReference.exponentialDecay(0.5, 0.1).bounded(0.01),
        alpha = 0.0004,
        gamma = 0.9,
        copyEach = 1000,
        referenceNet = neuralNet.as[NeuralNetworkRL]
      )
    language: scala
seeds:
  scenario: *random
  simulation: *random

environment:
  type: Continuous2DEnvironment
  parameters: [ ]
  global-programs:
    - time-distribution:
        type: DiracComb
        parameters: [0.01, 1]
      type: CentralAgent
      parameters: [ *learningInfo, *actionSpaceEvaluated, *learner, *environmentBox]
    - time-distribution:
        type: DiracComb
        parameters: [ 0.02, 0.01 ]
      type: SingleBlinker
      parameters: [ 200 ] # half width


network-model:
  type: ConnectWithinDistance #*connectionType
  parameters: [*range]

_reactions:
  - program: &program
      - time-distribution:
          type: NextWakeUp
          parameters: "nextWakeUp"
        type: Event
        actions:
          - type: RunScafiProgram
            parameters: [it.unibo.scafi.Main, *retentionTime]
      - program: send

deployments: ## i.e, how to place nodes
  type: Grid
  parameters: [0, 0, *width, *width, *spacing, *spacing, *randomness, *randomness]
  programs:
    - *program
  contents:
    - molecule: "nextWakeUp"
      concentration: *initial_clock
    - molecule: "actions"
      concentration: *actionSpace
    - molecule: "window"
      concentration: *windowHistory
    - molecule: "source"
      concentration: false
    - molecule: "weight"
      concentration: *weight
    - molecule: "full"
      concentration: false
export:
  - type: CSVExporter
    parameters:
      fileNameRoot: "experiment"
      exportPath: "build/exports/simulationDeep/full"
      fileExtension: "csv"
      interval: *exportInterval
    data:
      - time
      - molecule: ticks
        aggregators: [ sum ]
        value-filter: onlyfinite
      - molecule: nextWakeUp
        aggregators: [ mean ]
        value-filter: onlyfinite
      - molecule: reward
        aggregators: [ mean ]
        value-filter: onlyfinite
      - molecule: accumulatedReward
        aggregators: [ mean ]
        value-filter: onlyfinite
      - molecule: localComputation
        aggregators: [ sum ]
        value-filter: onlyfinite
      - molecule: groundTruth
        aggregators: [ sum ]
        value-filter: onlyfinite
  - type: CSVExporter
    parameters:
      fileNameRoot: "experiment"
      exportPath: "build/exports/simulationDeep/episode"
      fileExtension: "csv"
      interval: *episodeLength
    data:
      - time
      - molecule: ticks
        aggregators: [ sum ]
        value-filter: onlyfinite
      - molecule: accumulatedReward
        aggregators: [ mean ]
        value-filter: onlyfinite
      - molecule: accumulatedUnstableTime
        aggregators: [ mean ]
        value-filter: onlyfinite
      - type: DecayVariableExtractor
        parameters: [ ]


terminate:
  type: AfterTime
  parameters: [ *totalEpisodes ]